{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "class Team(object):\n",
    "    \n",
    "    def __init__(self, teamNumber, PRConstant, winrateVSStyles, repeatPenaltyArr, playerHealthArr, numOfGamesFinished):\n",
    "        \n",
    "        self.teamNumber = teamNumber\n",
    "        self.PRConstant = PRConstant\n",
    "        self.winrateVSStyles = winrateVSStyles\n",
    "        self.repeatPenaltyArr = repeatPenaltyArr\n",
    "        self.playerHealthArr = playerHealthArr\n",
    "        self.numOfGamesFinished = numOfGamesFinished\n",
    "    \n",
    "    def updateRepeatArr(self, action):\n",
    "        \"\"\"\n",
    "        used to update the repeat penalty style array\n",
    "        \"\"\"\n",
    "        self.repeatPenaltyArray[action] += 1\n",
    "        \n",
    "    def updatePlayerHealth(self): \n",
    "        \"\"\"\n",
    "        update the player health array\n",
    "        players have a certain probability of getting injured the more games into the series, the more likely it is:\n",
    "        \"\"\"\n",
    "        playerInjuryProb = 0.05 * 1.1**(self.numOfGamesFinished)\n",
    "        for k in range(len(self.playerHealthArr)):\n",
    "            self.playerHealthArr[k] = int(random.random() <= playerInjuryProb)\n",
    "        \n",
    "    def updateFinishedGames(self):\n",
    "        \"\"\"\n",
    "        udpate the games played\n",
    "        \"\"\"\n",
    "        self.numOfGamesFinished=self.numOfGamesFinished+1\n",
    "\n",
    "    def updateTeam(self, action):\n",
    "        self.updateRepeatArr(action)\n",
    "        self.updatePlayerHealth()\n",
    "        self.updateFinishedGames()\n",
    "        \n",
    "\n",
    "class State(object):\n",
    "    \n",
    "    def __init__(self, team1, team2):    \n",
    "        self.team1 = team1\n",
    "        self.team2 = team2\n",
    "\n",
    "def generate(state, action1, repeatPenaltyScaler=10):\n",
    "\n",
    "    team1 = state.team1\n",
    "    team2 = state.team2\n",
    "\n",
    "    #Update the power ratings\n",
    "    PRs1=team1.PRConstant-repeatPenaltyScaler*team1.repeatPenaltyArr\n",
    "    PRs2=team2.PRConstant-repeatPenaltyScaler*team2.repeatPenaltyArr\n",
    "\n",
    "    #UNIMPLEMENTED YET: update with the player injury update\n",
    "    \n",
    "    PR1_picked = PRs1[action1];\n",
    "    action2 = np.argmax(PRs2)\n",
    "    PR2_picked = PRs2[action2] #assume opponent always plays their most dominant style at the beginning\n",
    "\n",
    "    #scale them with (1-win rate) of the opponent vs the style they pick\n",
    "    WRs1=team1.winrateVSStyles\n",
    "    WRs2=team2.winrateVSStyles\n",
    "\n",
    "    PR1_picked = PR1_picked * (1 - WRs2[action1])\n",
    "    PR2_picked = PR2_picked * (1 - WRs1[action2])\n",
    "\n",
    "    #generate the reward by drawing from distribution\n",
    "    proba = PR1_picked/(PR1_picked+PR2_picked)\n",
    "    reward = int(random.random() < proba)\n",
    "\n",
    "    team1.updateTeam(action1)\n",
    "    team2.updateTeam(action2)\n",
    "    next_state = State(team1, team2)\n",
    "    \n",
    "    return reward, next_state\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
